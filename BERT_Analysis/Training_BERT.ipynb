{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wn4Fu4U9eC-8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fce0feb-668c-4bc5-81cd-c99f94cbd4e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  libportaudio2\n",
            "0 upgraded, 1 newly installed, 0 to remove and 62 not upgraded.\n",
            "Need to get 64.6 kB of archives.\n",
            "After this operation, 215 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libportaudio2 amd64 19.6.0-1 [64.6 kB]\n",
            "Fetched 64.6 kB in 0s (130 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libportaudio2:amd64.\n",
            "(Reading database ... 155639 files and directories currently installed.)\n",
            "Preparing to unpack .../libportaudio2_19.6.0-1_amd64.deb ...\n",
            "Unpacking libportaudio2:amd64 (19.6.0-1) ...\n",
            "Setting up libportaudio2:amd64 (19.6.0-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "\u001b[K     |████████████████████████████████| 643 kB 5.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 120 kB 46.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 44.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 28.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 10.9 MB 10.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 840 kB 41.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 36.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 56.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 87 kB 5.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 237 kB 44.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 50.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 55.1 MB 1.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 25.3 MB 1.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 57.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 99 kB 8.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 352 kB 67.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 48.3 MB 69 kB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 63.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 55.1 MB 144 kB/s \n",
            "\u001b[K     |████████████████████████████████| 55.1 MB 47 kB/s \n",
            "\u001b[K     |████████████████████████████████| 55.1 MB 1.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 55.1 MB 42 kB/s \n",
            "\u001b[K     |████████████████████████████████| 55.1 MB 118 kB/s \n",
            "\u001b[K     |████████████████████████████████| 55.1 MB 40 kB/s \n",
            "\u001b[K     |████████████████████████████████| 55.1 MB 136 kB/s \n",
            "\u001b[K     |████████████████████████████████| 55.1 MB 101 kB/s \n",
            "\u001b[K     |████████████████████████████████| 55.1 MB 47 kB/s \n",
            "\u001b[K     |████████████████████████████████| 42.6 MB 1.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 42.6 MB 1.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 42.6 MB 1.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 42.6 MB 2.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 42.6 MB 1.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 42.6 MB 1.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 42.6 MB 1.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 42.6 MB 1.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 42.6 MB 1.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 42.6 MB 1.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 42.6 MB 1.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 42.6 MB 1.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 42.6 MB 1.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 42.6 MB 1.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 42.6 MB 1.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 42.5 MB 1.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 213 kB 72.6 MB/s \n",
            "\u001b[?25h  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!sudo apt -y install libportaudio2\n",
        "!pip install -q tflite-model-maker-nightly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywLt_WAQH0yF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tflite_model_maker import model_spec, text_classifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tflite_model_maker.config import ExportFormat\n",
        "from tflite_model_maker.text_classifier import AverageWordVecSpec\n",
        "from tflite_model_maker.text_classifier import DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jq4KV5gvPPka"
      },
      "source": [
        "## Loading Amazon Review Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1cWJzurIFfQ"
      },
      "outputs": [],
      "source": [
        "txt = open(\"/content/drive/MyDrive/EY/test.ft.txt\", \"r\").read()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6oNv3KGPhlT"
      },
      "source": [
        "```__label__1 : -ve  -> 0```\n",
        "\n",
        "```__label__2 : +ve  -> 1```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8T9npbmPXxm"
      },
      "outputs": [],
      "source": [
        "X, y = [], []\n",
        "for i in txt.split(\"\\n\")[:-1]:\n",
        "  split_i = i.split(\" \", 1)\n",
        "  if split_i[0] == \"__label__1\":\n",
        "    X.append(0)\n",
        "  else:\n",
        "    X.append(1)\n",
        "  y.append(split_i[1])\n",
        "\n",
        "#######\n",
        "# Shortening Data  \n",
        "X, y = X[:5000], y[:5000]\n",
        "#######\n",
        "Data = pd.DataFrame([X,y]).T\n",
        "Data.columns = [\"y\", \"X\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8DkYhwPYS0M",
        "outputId": "022b8f18-71cf-4c0c-cbb0-d054b5b83a5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HbSyb3t9fc-l"
      },
      "outputs": [],
      "source": [
        "train_data, test = train_test_split(Data, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4akm6MetPJD"
      },
      "outputs": [],
      "source": [
        "train_data.to_csv(\"/content/drive/MyDrive/EY/train.csv\")\n",
        "test.to_csv(\"/content/drive/MyDrive/EY/test.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_FYBG6vuNAQ"
      },
      "source": [
        "## BERT Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAXC1N7yQxtw"
      },
      "outputs": [],
      "source": [
        "mb_spec = model_spec.get('mobilebert_classifier')\n",
        "# mb_spec = model_spec.get('average_word_vec')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0mlwmZ_TjI9J"
      },
      "outputs": [],
      "source": [
        "# ds = tf.data.Dataset.from_tensor_slices(train_data.to_dict(orient=\"list\"))\n",
        "train_data = DataLoader.from_csv(\n",
        "      filename=\"/content/drive/MyDrive/EY/train.csv\",\n",
        "      text_column='X',\n",
        "      label_column='y',\n",
        "      model_spec=mb_spec,\n",
        "      is_training=True)\n",
        "test_data = DataLoader.from_csv(\n",
        "      filename=\"/content/drive/MyDrive/EY/test.csv\",\n",
        "      text_column='X',\n",
        "      label_column='y',\n",
        "      model_spec=mb_spec,\n",
        "      is_training=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qilukr4wd9sH",
        "outputId": "5d913475-ac11-4f61-b652-c8cf5d58c445"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Retraining the models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Retraining the models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "83/83 [==============================] - 1842s 21s/step - loss: 1.0176 - test_accuracy: 0.5502\n",
            "Epoch 2/2\n",
            "83/83 [==============================] - 1795s 22s/step - loss: 0.3694 - test_accuracy: 0.8441\n",
            "Epoch 3/3\n",
            "83/83 [==============================] - 1833s 22s/step - loss: 0.1969 - test_accuracy: 0.9322\n",
            "Epoch 4/4\n",
            "83/83 [==============================] - 1836s 22s/step - loss: 0.1171 - test_accuracy: 0.9704\n",
            "Epoch 5/5\n",
            "83/83 [==============================] - 1802s 22s/step - loss: 0.0707 - test_accuracy: 0.9842\n",
            "Epoch 6/6\n",
            "83/83 [==============================] - 1837s 22s/step - loss: 0.0444 - test_accuracy: 0.9900\n",
            "Epoch 7/7\n",
            "83/83 [==============================] - 1816s 22s/step - loss: 0.0246 - test_accuracy: 0.9947\n",
            "Epoch 8/8\n",
            "83/83 [==============================] - 1823s 22s/step - loss: 0.0167 - test_accuracy: 0.9967\n"
          ]
        }
      ],
      "source": [
        "model = text_classifier.create(train_data, model_spec=mb_spec, epochs=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKBE_h6byd6_"
      },
      "outputs": [],
      "source": [
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cWS0TlFEy2_1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57583421-2cbc-4051-b4e0-da15f39df0cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 128s 4s/step - loss: 0.4697 - test_accuracy: 0.9040\n"
          ]
        }
      ],
      "source": [
        "loss, acc = model.evaluate(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.export(\"/content/drive/MyDrive/EY/Model_90\", export_format=[ExportFormat.LABEL, ExportFormat.VOCAB, ExportFormat.SAVED_MODEL, ExportFormat.TFLITE])"
      ],
      "metadata": {
        "id": "t1fHgqsFvzRx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5cd8cc8-3c40-4572-bfbb-c2c5746f0371"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpaqnkkxgm/saved_model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpaqnkkxgm/saved_model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Vocab file and label file are inside the TFLite model with metadata.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Vocab file and label file are inside the TFLite model with metadata.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Saved vocabulary in /tmp/tmpjly59l_m/vocab.txt.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Saved vocabulary in /tmp/tmpjly59l_m/vocab.txt.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Saving labels in /tmp/tmpjly59l_m/labels.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Saving labels in /tmp/tmpjly59l_m/labels.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished populating metadata and associated file to the model:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished populating metadata and associated file to the model:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:/content/drive/MyDrive/EY/Model_90/model.tflite\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:/content/drive/MyDrive/EY/Model_90/model.tflite\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:The associated file that has been been packed to the model is:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:The associated file that has been been packed to the model is:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:['vocab.txt', 'labels.txt']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:['vocab.txt', 'labels.txt']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:TensorFlow Lite model exported successfully: /content/drive/MyDrive/EY/Model_90/model.tflite\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:TensorFlow Lite model exported successfully: /content/drive/MyDrive/EY/Model_90/model.tflite\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/EY/Model_90/saved_model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/EY/Model_90/saved_model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Export a separated vocab file even though vocab file is already inside the TFLite model with metadata.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Export a separated vocab file even though vocab file is already inside the TFLite model with metadata.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Saved vocabulary in /content/drive/MyDrive/EY/Model_90/vocab.txt.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Saved vocabulary in /content/drive/MyDrive/EY/Model_90/vocab.txt.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Export a separated label file even though label file is already inside the TFLite model with metadata.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Export a separated label file even though label file is already inside the TFLite model with metadata.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Saving labels in /content/drive/MyDrive/EY/Model_90/labels.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Saving labels in /content/drive/MyDrive/EY/Model_90/labels.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kJdxKQbtYCcb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}